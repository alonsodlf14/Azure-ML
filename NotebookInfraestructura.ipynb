{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# First sample with Azure Machine Learning\n",
        "\n",
        "## Pre-requirements\n",
        "\n",
        "> **!NOTE**\n",
        "> Python code will be executed in the compute instance (by default a STANDARD_E4DS_V4 - Estimated cost $0.35/hr when running)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Create handle to workspace\n",
        "\n",
        "Create _ml_client_ for a handle to our workspace (configure workspace name, subscription, resource group) . \n",
        "\n",
        "We'll then use _ml_client_ to manage resources and jobs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1719153951408
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "# authenticate\n",
        "credential = DefaultAzureCredential()\n",
        "\n",
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=\"99549e94-696b-4f04-b0d5-72fd101c704f\",\n",
        "    resource_group_name=\"sebastian.delafuente-rg\",\n",
        "    workspace_name=\"Azuremlalover\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Create training script\n",
        "\n",
        "Let's start by creating the training script - the main.py Python file.\n",
        "\n",
        "First create a source folder for the script. The script handles the preprocessing of the data, splitting it into test and train data. It then consumes this data to train a tree based model and return the output model. [MLFlow](https://learn.microsoft.com/azure/machine-learning/how-to-log-mlflow-models) will be used to log the parameters and metrics during our pipeline run. \n",
        "The cell below uses IPython magic to write the training script into the directory you just created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "editable": true,
        "gather": {
          "logged": 1719153956723
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "run_control": {
          "frozen": false
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "train_src_dir = \"./src\"\n",
        "os.makedirs(train_src_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "editable": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "run_control": {
          "frozen": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./src/main.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile {train_src_dir}/main.py\n",
        "import os\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn import preprocessing\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function of the script.\"\"\"\n",
        "\n",
        "    # input and output arguments\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--data\", type=str, help=\"path to input data\")\n",
        "    parser.add_argument(\"--test_train_ratio\", type=float, required=False, default=0.25)\n",
        "    parser.add_argument(\"--n_estimators\", required=False, default=100, type=int)\n",
        "    parser.add_argument(\"--learning_rate\", required=False, default=0.1, type=float)\n",
        "    parser.add_argument(\"--registered_model_name\", type=str, help=\"model name\")\n",
        "    args = parser.parse_args()\n",
        "   \n",
        "    # Start Logging\n",
        "    mlflow.start_run()\n",
        "\n",
        "    # enable autologging\n",
        "    mlflow.sklearn.autolog()\n",
        "\n",
        "    ###################\n",
        "    #<prepare the data>\n",
        "    ###################\n",
        "    print(\" \".join(f\"{k}={v}\" for k, v in vars(args).items()))\n",
        "\n",
        "    print(\"input data:\", args.data)\n",
        "    \n",
        "    stars_df = pd.read_csv(args.data)\n",
        "\n",
        "    print(stars_df.head(3))\n",
        "\n",
        "    #Quitar columnas que no añaden informacion relevante\n",
        "    stars_df = stars_df.drop(['spec_obj_ID'], axis = 1)\n",
        "    stars_df = stars_df.drop(['fiber_ID'], axis = 1)\n",
        "    stars_df = stars_df.drop(['field_ID'], axis = 1)\n",
        "    stars_df = stars_df.drop(['plate'], axis = 1)\n",
        "    stars_df = stars_df.drop(['MJD'], axis = 1)\n",
        "\n",
        "\n",
        "    #Cambiar la clase a etiqueta numerica\n",
        "\n",
        "    classValues = stars_df['class'].values\n",
        "\n",
        "    le = preprocessing.LabelEncoder()     \n",
        "    classLabelized = le.fit_transform(classValues)\n",
        "\n",
        "    stars_df['class'] = classLabelized\n",
        "\n",
        "\n",
        "    mlflow.log_metric(\"num_samples\", stars_df.shape[0])\n",
        "    mlflow.log_metric(\"num_features\", stars_df.shape[1] - 1)\n",
        "\n",
        "    train_df, test_df = train_test_split(\n",
        "        stars_df,\n",
        "        test_size=args.test_train_ratio,\n",
        "    )\n",
        "    ####################\n",
        "    #</prepare the data>\n",
        "    ####################\n",
        "\n",
        "    ##################\n",
        "    #<train the model>\n",
        "    ##################\n",
        "    # Extracting the label column\n",
        "    y_train = train_df.pop(\"class\")\n",
        "\n",
        "    # convert the dataframe values to array\n",
        "    X_train = train_df.values\n",
        "\n",
        "    # Extracting the label column\n",
        "    y_test = test_df.pop(\"class\")\n",
        "\n",
        "    # convert the dataframe values to array\n",
        "    X_test = test_df.values\n",
        "\n",
        "    print(f\"Training with data of shape {X_train.shape}\")\n",
        "\n",
        "    clf = GradientBoostingClassifier(\n",
        "        n_estimators=args.n_estimators, learning_rate=args.learning_rate\n",
        "    )\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    ###################\n",
        "    #</train the model>\n",
        "    ###################\n",
        "\n",
        "    ##########################\n",
        "    #<save and register model>\n",
        "    ##########################\n",
        "    # Registering the model to the workspace\n",
        "    print(\"Registering the model via MLFlow\")\n",
        "    mlflow.sklearn.log_model(\n",
        "        sk_model=clf,\n",
        "        registered_model_name=args.registered_model_name,\n",
        "        artifact_path=args.registered_model_name,\n",
        "    )\n",
        "\n",
        "    # Saving the model to a file\n",
        "    mlflow.sklearn.save_model(\n",
        "        sk_model=clf,\n",
        "        path=os.path.join(args.registered_model_name, \"trained_model\"),\n",
        "    )\n",
        "    ###########################\n",
        "    #</save and register model>\n",
        "    ###########################\n",
        "    \n",
        "    # Stop Logging\n",
        "    mlflow.end_run()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "As you can see in this script, once the model is trained, the model file is saved and registered to the workspace. Now you can use the registered model in inferencing endpoints.\n",
        "\n",
        "You might need to select **Refresh** to see the new folder and script in your **Files**.\n",
        "\n",
        "## Create a compute cluster, a scalable way to run a training job (Optional)\n",
        "\n",
        "You can **skip this step** if you want to use **serverless compute** to run the training job. Through serverless compute, Azure Machine Learning takes care of creating, scaling, deleting, patching and managing compute, along with providing managed network isolation, reducing the burden on you. \n",
        "\n",
        "You already have a compute instance, which you're using to run the notebook.  Now you'll add a second type of compute, a **compute cluster** that you'll use to run your training job. While a compute instance is a single node machine, a compute cluster can be single or multi-node machines with Linux or Windows OS, or a specific compute fabric like Spark.\n",
        "\n",
        "You'll provision a Linux compute cluster. See the [full list on VM sizes and prices](https://azure.microsoft.com/pricing/details/machine-learning/) .\n",
        "\n",
        "For this example, you only need a basic cluster, so you'll use a Standard_DS3_v2 model with 4 vCPU cores, 14GB RAM.\n",
        "\n",
        "> **!NOTE**\n",
        ">  STANDARD_DS3_v2 - Estimated cost $0.27/per node)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "editable": true,
        "gather": {
          "logged": 1719153989215
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "run_control": {
          "frozen": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You already have a cluster named cpu-cluster, we'll reuse it as is.\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml.entities import AmlCompute\n",
        "\n",
        "# Name assigned to the compute cluster\n",
        "cpu_compute_target = \"cpu-cluster\"\n",
        "\n",
        "try:\n",
        "    # let's see if the compute target already exists\n",
        "    cpu_cluster = ml_client.compute.get(cpu_compute_target)\n",
        "    print(\n",
        "        f\"You already have a cluster named {cpu_compute_target}, we'll reuse it as is.\"\n",
        "    )\n",
        "\n",
        "except Exception:\n",
        "    print(\"Creating a new cpu compute target...\")\n",
        "\n",
        "    # Let's create the Azure Machine Learning compute object with the intended parameters\n",
        "    # if you run into an out of quota error, change the size to a comparable VM that is available.\\\n",
        "    # Learn more on https://azure.microsoft.com/en-us/pricing/details/machine-learning/.\n",
        "    cpu_cluster = AmlCompute(\n",
        "        name=cpu_compute_target,\n",
        "        # Azure Machine Learning Compute is the on-demand VM service\n",
        "        type=\"amlcompute\",\n",
        "        # VM Family\n",
        "        size=\"STANDARD_DS3_V2\",\n",
        "        # Minimum running nodes when there is no job running\n",
        "        min_instances=0,\n",
        "        # Nodes in cluster\n",
        "        max_instances=4,\n",
        "        # How many seconds will the node running after the job termination\n",
        "        idle_time_before_scale_down=180,\n",
        "        # Dedicated or LowPriority. The latter is cheaper but there is a chance of job termination\n",
        "        tier=\"Dedicated\",\n",
        "    )\n",
        "    print(\n",
        "        f\"AMLCompute with name {cpu_cluster.name} will be created, with compute size {cpu_cluster.size}\"\n",
        "    )\n",
        "    # Now, we pass the object to MLClient's create_or_update method\n",
        "    cpu_cluster = ml_client.compute.begin_create_or_update(cpu_cluster)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Configure the job and the command to run the training script\n",
        "\n",
        " The command script:\n",
        "* Use the compute cluster to run the command if you created it or use serverless compute by not specifying any compute.\n",
        "* Use an *environment* that defines software and runtime libraries needed for the training script. Azure Machine Learning provides many curated or ready-made environments, which are useful for common training and inference scenarios. You'll use one of those environments here (to learn how to create a custom environment read the [Train a model](https://learn.microsoft.com/en-us/azure/machine-learning/tutorial-train-model?view=azureml-api-2) tutorial). \n",
        "* Configure the command line action itself - `python main.py` in this case. The inputs/outputs are accessible in the command via the `${{ ... }}` notation.\n",
        "* In this sample, we access the data from a file on the internet. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "editable": true,
        "gather": {
          "logged": 1719153995223
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "run_control": {
          "frozen": false
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import command\n",
        "from azure.ai.ml import Input\n",
        "\n",
        "registered_model_name = \"star_prediction_model\"\n",
        "\n",
        "job = command(\n",
        "    inputs=dict(\n",
        "        data=Input(\n",
        "            type=\"uri_file\",\n",
        "            path=\"https://raw.githubusercontent.com/Hertorias/INSO4-AprendizajeAutomaticoII/main/Practica2/data/star_class_clean.csv\",\n",
        "        ),\n",
        "        test_train_ratio=0.2,\n",
        "        learning_rate=0.25,\n",
        "        registered_model_name=registered_model_name,\n",
        "    ),\n",
        "    code=\"./src/\",  # location of source code\n",
        "    command=\"python main.py --data ${{inputs.data}} --test_train_ratio ${{inputs.test_train_ratio}} --learning_rate ${{inputs.learning_rate}} --registered_model_name ${{inputs.registered_model_name}}\",\n",
        "    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n",
        "    compute=\"cpu-cluster\", #delete this line to use serverless compute\n",
        "    display_name=\"star_type_prediction\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Submite the job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "editable": true,
        "gather": {
          "logged": 1719154004358
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "run_control": {
          "frozen": false
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "\u001b[32mUploading src (0.0 MBs): 100%|██████████| 3757/3757 [00:00<00:00, 98957.55it/s]\n",
            "\u001b[39m\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>azure-machinelearning-labs-main</td><td>joyful_plow_jrf08n8frv</td><td>command</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/joyful_plow_jrf08n8frv?wsid=/subscriptions/99549e94-696b-4f04-b0d5-72fd101c704f/resourcegroups/hector.asorey-rg/workspaces/Azuremlalover&amp;tid=6afea85d-c323-4270-b69d-a4fb3927c254\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
            ],
            "text/plain": [
              "Command({'parameters': {}, 'init': False, 'name': 'joyful_plow_jrf08n8frv', 'type': 'command', 'status': 'Starting', 'log_files': None, 'description': None, 'tags': {}, 'properties': {'_azureml.ComputeTargetType': 'amlctrain', '_azureml.ClusterName': 'cpu-cluster', 'ContentSnapshotId': 'cb786c24-5bf9-4e08-b4fb-1228fb9a3bd9'}, 'print_as_yaml': False, 'id': '/subscriptions/99549e94-696b-4f04-b0d5-72fd101c704f/resourceGroups/hector.asorey-rg/providers/Microsoft.MachineLearningServices/workspaces/Azuremlalover/jobs/joyful_plow_jrf08n8frv', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/mlcomputeaso/code/Users/hector.asorey/azure-machinelearning-labs-main', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f13514ac700>, 'serialize': <msrest.serialization.Serializer object at 0x7f135147e3e0>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <TraceLogger attr_dict (WARNING)>, 'display_name': 'star_type_prediction', 'experiment_name': 'azure-machinelearning-labs-main', 'compute': 'cpu-cluster', 'services': {'Tracking': {'endpoint': 'azureml://northeurope.api.azureml.ms/mlflow/v1.0/subscriptions/99549e94-696b-4f04-b0d5-72fd101c704f/resourceGroups/hector.asorey-rg/providers/Microsoft.MachineLearningServices/workspaces/Azuremlalover?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/joyful_plow_jrf08n8frv?wsid=/subscriptions/99549e94-696b-4f04-b0d5-72fd101c704f/resourcegroups/hector.asorey-rg/workspaces/Azuremlalover&tid=6afea85d-c323-4270-b69d-a4fb3927c254', 'type': 'Studio'}}, 'comment': None, 'job_inputs': {'data': {'type': 'uri_file', 'path': 'https://raw.githubusercontent.com/Hertorias/INSO4-AprendizajeAutomaticoII/main/Practica2/data/star_class_clean.csv', 'mode': 'ro_mount'}, 'test_train_ratio': '0.2', 'learning_rate': '0.25', 'registered_model_name': 'star_prediction_model'}, 'job_outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.joyful_plow_jrf08n8frv', 'mode': 'rw_mount'}}, 'inputs': {'data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f135147ff70>, 'test_train_ratio': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f135147feb0>, 'learning_rate': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f135147ffd0>, 'registered_model_name': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f13514c99c0>}, 'outputs': {'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f13514ca1a0>}, 'component': CommandComponent({'latest_version': None, 'intellectual_property': None, 'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'joyful_plow_jrf08n8frv', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/mlcomputeaso/code/Users/hector.asorey/azure-machinelearning-labs-main', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f13514ac700>, 'serialize': <msrest.serialization.Serializer object at 0x7f135147e320>, 'command': 'python main.py --data ${{inputs.data}} --test_train_ratio ${{inputs.test_train_ratio}} --learning_rate ${{inputs.learning_rate}} --registered_model_name ${{inputs.registered_model_name}}', 'code': '/subscriptions/99549e94-696b-4f04-b0d5-72fd101c704f/resourceGroups/hector.asorey-rg/providers/Microsoft.MachineLearningServices/workspaces/Azuremlalover/codes/65a7db19-95d6-4777-9c03-5a2b0a692e95/versions/1', 'environment_variables': {}, 'environment': 'azureml:AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest', 'distribution': None, 'resources': None, 'queue_settings': None, 'version': None, 'schema': None, 'type': 'command', 'display_name': 'star_type_prediction', 'is_deterministic': True, 'inputs': {'data': {'type': 'uri_file', 'path': 'https://raw.githubusercontent.com/Hertorias/INSO4-AprendizajeAutomaticoII/main/Practica2/data/star_class_clean.csv', 'mode': 'ro_mount'}, 'test_train_ratio': {'type': 'string', 'default': '0.2'}, 'learning_rate': {'type': 'string', 'default': '0.25'}, 'registered_model_name': {'type': 'string', 'default': 'star_prediction_model'}}, 'outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.joyful_plow_jrf08n8frv', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Starting', 'parameters': {}}, 'additional_includes': []}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': {'endpoint': 'azureml://northeurope.api.azureml.ms/mlflow/v1.0/subscriptions/99549e94-696b-4f04-b0d5-72fd101c704f/resourceGroups/hector.asorey-rg/providers/Microsoft.MachineLearningServices/workspaces/Azuremlalover?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/joyful_plow_jrf08n8frv?wsid=/subscriptions/99549e94-696b-4f04-b0d5-72fd101c704f/resourcegroups/hector.asorey-rg/workspaces/Azuremlalover&tid=6afea85d-c323-4270-b69d-a4fb3927c254', 'type': 'Studio'}}, 'status': 'Starting', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f13514ac700>}, 'instance_id': '881db268-aab4-4b1f-b74d-d159c26b1f0f', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': 'azureml:AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest', 'resources': {'instance_count': 1, 'shm_size': '2g'}, 'queue_settings': None, 'swept': False})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ml_client.create_or_update(job)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## View job output and wait for job completion\n",
        "\n",
        "View the job in Azure Machine Learning studio by selecting the link in the output of the previous cell. \n",
        "\n",
        "The output of this job will look like this in the Azure Machine Learning studio. Explore the tabs for various details like metrics, outputs etc. Once completed, the job will register a model in your workspace as a result of training. \n",
        "\n",
        "> [!IMPORTANT]\n",
        "> Wait until the status of the job is complete before returning to this notebook to continue. The job will take 2 to 3 minutes to run. It could take longer (up to 10 minutes) if the compute cluster has been scaled down to zero nodes and custom environment is still building."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Deploy the model as an online endpoint\n",
        "\n",
        "Now deploy your machine learning model as a web service in the Azure cloud, an [`online endpoint`](https://docs.microsoft.com/azure/machine-learning/concept-endpoints).\n",
        "\n",
        "To deploy a machine learning service, you'll use the model you registered."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Create a new online endpoint\n",
        "\n",
        "Now that you have a registered model, it's time to create your online endpoint. The endpoint name needs to be unique in the entire Azure region. For this tutorial, you'll create a unique name using [`UUID`](https://en.wikipedia.org/wiki/Universally_unique_identifier#:~:text=A%20universally%20unique%20identifier%20).\n",
        "\n",
        "> [!NOTE]\n",
        "> Expect the endpoint creation to take a few minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "editable": true,
        "gather": {
          "logged": 1719156218108
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "run_control": {
          "frozen": false
        }
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "\n",
        "# Creating a unique name for the endpoint\n",
        "online_endpoint_name = \"stars-pred-endpoint-\" + str(uuid.uuid4())[:8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "editable": true,
        "gather": {
          "logged": 1719156314554
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "run_control": {
          "frozen": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Endpoint stars-pred-endpoint-77c08a9d provisioning state: Succeeded\n"
          ]
        }
      ],
      "source": [
        "# Expect the endpoint creation to take a few minutes\n",
        "from azure.ai.ml.entities import (\n",
        "    ManagedOnlineEndpoint,\n",
        "    ManagedOnlineDeployment,\n",
        "    Model,\n",
        "    Environment,\n",
        ")\n",
        "\n",
        "# create an online endpoint\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name=online_endpoint_name,\n",
        "    description=\"this is an online endpoint\",\n",
        "    auth_mode=\"key\",\n",
        "    tags={\n",
        "        \"training_dataset\": \"stars\",\n",
        "        \"model_type\": \"sklearn.GradientBoostingClassifier\",\n",
        "    },\n",
        ")\n",
        "\n",
        "endpoint = ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
        "\n",
        "print(f\"Endpoint {endpoint.name} provisioning state: {endpoint.provisioning_state}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Once the endpoint has been created, you can retrieve it as below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1719156323508
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Endpoint \"stars-pred-endpoint-77c08a9d\" with provisioning state \"Succeeded\" is retrieved\n"
          ]
        }
      ],
      "source": [
        "#jessica\n",
        "#online_endpoint_name=\"credit-endpoint-c5241ea2\"\n",
        "\n",
        "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\n",
        "\n",
        "print(\n",
        "    f'Endpoint \"{endpoint.name}\" with provisioning state \"{endpoint.provisioning_state}\" is retrieved'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Deploy the model to the endpoint\n",
        "\n",
        "Once the endpoint is created, deploy the model with the entry script. Each endpoint can have multiple deployments. Direct traffic to these deployments can be specified using rules. Here you'll create a single deployment that handles 100% of the incoming traffic. We have chosen a color name for the deployment, for example, blue, green, red deployments, which is arbitrary.\n",
        "\n",
        "You can check the Models page on Azure Machine Learning studio, to identify the latest version of your registered model. Alternatively, the code below will retrieve the latest version number for you to use.\n",
        "\n",
        "> [!NOTE]\n",
        "> Este despliegue tardará entre 6 y 8 minutos aproximadamente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1719156326755
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Latest model is version \"3\" \n"
          ]
        }
      ],
      "source": [
        "# Let's pick the latest version of the model\n",
        "latest_model_version = max(\n",
        "    [int(m.version) for m in ml_client.models.list(name=\"star_prediction_model\")]\n",
        ")\n",
        "print(f'Latest model is version \"{latest_model_version}\" ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1719156923501
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Instance type Standard_DS2_v2 may be too small for compute resources. Minimum recommended compute SKU is Standard_DS3_v2 for general purpose endpoints. Learn more about SKUs here: https://learn.microsoft.com/en-us/azure/machine-learning/referencemanaged-online-endpoints-vm-sku-list\n",
            "Check: endpoint stars-pred-endpoint-77c08a9d exists\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".............................................................................................................."
          ]
        }
      ],
      "source": [
        "# picking the model to deploy. Here we use the latest version of our registered model\n",
        "model = ml_client.models.get(name=\"star_prediction_model\", version=latest_model_version)\n",
        "\n",
        "# Expect this deployment to take approximately 6 to 8 minutes.\n",
        "# create an online deployment.\n",
        "# if you run into an out of quota error, change the instance_type to a comparable VM that is available.\\\n",
        "# Learn more on https://azure.microsoft.com/en-us/pricing/details/machine-learning/.\n",
        "\n",
        "green_deployment = ManagedOnlineDeployment(\n",
        "    name=\"green\",\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    model=model,\n",
        "    instance_type=\"Standard_DS2_v2\",\n",
        "    instance_count=1,\n",
        ")\n",
        "\n",
        "green_deployment = ml_client.begin_create_or_update(green_deployment).result()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Test with a sample query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1718641351950
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "deploy_dir = \"./deploy\"\n",
        "os.makedirs(deploy_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing ./deploy/sample-request.json\n"
          ]
        }
      ],
      "source": [
        "%%writefile {deploy_dir}/sample-request.json\n",
        "\n",
        "{\n",
        "  \"input_data\": {\n",
        "    \"columns\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
        "    \"index\": [0],\n",
        "    \"data\": [\n",
        "        [6.6, 60.6, 600, 650, 620, 630, 640, 0.6, 1100, 59500]\n",
        "    ]\n",
        "  },\n",
        "  \"params\": {}\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1718641361005
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "ename": "HttpResponseError",
          "evalue": "(None) An unexpected error occurred in scoring script. Check the logs for more info.\nCode: None\nMessage: An unexpected error occurred in scoring script. Check the logs for more info.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHttpResponseError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# test the green deployment with some sample data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monline_endpoints\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monline_endpoint_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./deploy/sample-request.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeployment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgreen\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/tracing/decorator.py:76\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_telemetry/activity.py:263\u001b[0m, in \u001b[0;36mmonitor_with_activity.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m log_activity(logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions):\n\u001b[0;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_online_endpoint_operations.py:357\u001b[0m, in \u001b[0;36mOnlineEndpointOperations.invoke\u001b[0;34m(self, endpoint_name, request_file, deployment_name, input_data, params_override, local, **kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     headers[EndpointInvokeFields\u001b[38;5;241m.\u001b[39mMODEL_DEPLOYMENT] \u001b[38;5;241m=\u001b[39m deployment_name\n\u001b[1;32m    356\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requests_pipeline\u001b[38;5;241m.\u001b[39mpost(endpoint\u001b[38;5;241m.\u001b[39mproperties\u001b[38;5;241m.\u001b[39mscoring_uri, json\u001b[38;5;241m=\u001b[39mdata, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[0;32m--> 357\u001b[0m \u001b[43mvalidate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mtext()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_utils/_endpoint_utils.py:128\u001b[0m, in \u001b[0;36mvalidate_response\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m    122\u001b[0m error_map \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;241m401\u001b[39m: ClientAuthenticationError,\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;241m404\u001b[39m: ResourceNotFoundError,\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;241m409\u001b[39m: ResourceExistsError,\n\u001b[1;32m    126\u001b[0m }\n\u001b[1;32m    127\u001b[0m map_error(status_code\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code, response\u001b[38;5;241m=\u001b[39mresponse, error_map\u001b[38;5;241m=\u001b[39merror_map)\n\u001b[0;32m--> 128\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response\u001b[38;5;241m=\u001b[39mresponse, message\u001b[38;5;241m=\u001b[39mfailure_msg, error_format\u001b[38;5;241m=\u001b[39mARMErrorFormat)\n",
            "\u001b[0;31mHttpResponseError\u001b[0m: (None) An unexpected error occurred in scoring script. Check the logs for more info.\nCode: None\nMessage: An unexpected error occurred in scoring script. Check the logs for more info."
          ]
        }
      ],
      "source": [
        "# test the green deployment with some sample data\n",
        "ml_client.online_endpoints.invoke(\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    request_file=\"./deploy/sample-request.json\",\n",
        "    deployment_name=\"green\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Clean up resources\n",
        "\n",
        "If you're not going to use the endpoint, delete it to stop using the resource.  Make sure no other deployments are using an endpoint before you delete it.\n",
        "\n",
        "\n",
        "> [!NOTE]\n",
        "> Expect the complete deletion to take approximately 20 minutes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1718703074408
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<azure.core.polling._poller.LROPoller at 0x7f2c023dcee0>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".........."
          ]
        }
      ],
      "source": [
        "ml_client.online_endpoints.begin_delete(name=online_endpoint_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Next Steps\n",
        "\n",
        "You now have an Azure Machine Learning workspace, which contains a compute instance to use for your development environment.\n",
        "\n",
        "Continue on to learn how to use the compute instance to run notebooks and scripts in the Azure Machine Learning cloud. \n",
        "\n",
        "|Tutorial  |Description  |\n",
        "|---------|---------|\n",
        "| [Tutorial: Upload, access and explore your data in Azure Machine Learning](https://learn.microsoft.com/azure/tutorial-explore-data)     |  Store large data in the cloud and retrieve it from notebooks and scripts |\n",
        "| [Tutorial: Model development on a cloud workstation](https://learn.microsoft.com/azure/tutorial-cloud-workstation) | Start prototyping and developing machine learning models |\n",
        "| [Tutorial: Train a model in Azure Machine Learning](https://learn.microsoft.com/azure/tutorial-train-model) |    Dive in to the details of training a model     |\n",
        "| [Tutorial: Deploy a model as an online endpoint](https://learn.microsoft.com/azure/tutorial-deploy-model)  |   Dive in to the details of deploying a model      |\n",
        "| [Tutorial: Create production machine learning pipelines](https://learn.microsoft.com/azure/tutorial-pipeline-python-sdk) | Split a complete machine learning task into a multistep workflow. |"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
